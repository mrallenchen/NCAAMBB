{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab names for all NCAA teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sports-reference.com/cbb/schools/\"\n",
    "response = requests.get(url)\n",
    "teams_text = response.text\n",
    "team_soup = BeautifulSoup(teams_text, \"lxml\")\n",
    "team_table = team_soup.find('table')\n",
    "team_rows = team_table.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that after every 20 teams, there is another header row\n",
    "teams_list = {}\n",
    "for i in [i for i in range(1,len(team_rows)) if i % 21 != 0]:\n",
    "    items = team_rows[i].find_all('td')\n",
    "    link = items[0].find('a')\n",
    "    school, url = link.text, link['href']\n",
    "    teams_list[school] = [url] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('teams_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(teams_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary of D1 Teams for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teams(teams_list, season):\n",
    "    '''\n",
    "    Find teams in D1 for particular season\n",
    "    \n",
    "    input: season, this will be the year of interest\n",
    "    output: a list of all the D1 teams that played that year, with their formal name\n",
    "    '''\n",
    "    season_teams = {}\n",
    "    for team in teams_list.keys():\n",
    "        if int(teams_list[team][3]) <= season <= int(teams_list[team][4]):\n",
    "            season_teams[team] = teams_list[team]\n",
    "    return season_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_name_dict(season_teams, season):\n",
    "    '''\n",
    "    Create team_lookup for names - url name as key, values include name, formal name, and team url\n",
    "    \n",
    "    input: the teams identified for a particular season, the year of the season\n",
    "    output: a dictionary where the keys are the simple names \n",
    "    '''\n",
    "    team_lookup = {}\n",
    "    for key in season_teams:\n",
    "        sched_url = \"https://www.sports-reference.com\" + season_teams[key][0] + str(season) +\"-schedule.html\"\n",
    "        sched_response = requests.get(sched_url)\n",
    "        sched_text = sched_response.text\n",
    "        sched_soup = BeautifulSoup(sched_text,\"lxml\")\n",
    "        sched_table = sched_soup.find('table')\n",
    "        simple_name = re.split(\"\\/\",season_teams[key][0])[3]\n",
    "        sched_rows = sched_table.find_all('tr')\n",
    "        name = sched_table.find('a').text\n",
    "        formal_name = season_teams[key][1]\n",
    "        team_lookup[simple_name] = [name] + [formal_name] + [season_teams[key][0]]\n",
    "    return team_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis was done for years 2014-2019, omitting 2020 because the season was cut short due to covid-19\n",
    "for i in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
    "    season_teams = teams(teams_list, i)\n",
    "    team_lookup = team_name_dict(season_teams, 2019)\n",
    "    with open(f'team_lookup_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(team_lookup, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_lookup = pickle.load(open('team_lookup.pickle', \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to webscrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_gamelog(season_teams, season):\n",
    "    '''\n",
    "    This grabs the gamelogs for all teams, for the season that is specified.\n",
    "    \n",
    "    Input: Dictionary where the keys are the teams for specified season; specified season\n",
    "    Output: A dictionary, where each key stores a season's worth of individual game statistics for one team;\n",
    "            The dictionary will hold all teams' information\n",
    "    \n",
    "    '''\n",
    "    gamelog = {}\n",
    "    for key in season_teams:\n",
    "        game_url = \"https://www.sports-reference.com\" + season_teams[key][0] + str(season) +\"-gamelogs.html\"\n",
    "        print(game_url)\n",
    "        game_response = requests.get(game_url)\n",
    "        gamelog_text = game_response.text\n",
    "        gamelog_soup = BeautifulSoup(gamelog_text,\"lxml\")\n",
    "        gamelog_table = gamelog_soup.find('table')\n",
    "        gamelog_rows = gamelog_table.find_all('tr')\n",
    "        team = re.split(\"\\/\",season_teams[key][0])[3]\n",
    "        for i in [i for i in range(2,len(gamelog_rows)) if i % 22 != 0 and i % 23 != 0 and i % 44 != 0 and i % 45 != 0]:\n",
    "            items = gamelog_rows[i].find_all('td')\n",
    "            link = items[0].find('a')\n",
    "            if link == None:\n",
    "                pass\n",
    "            else:\n",
    "                date, url = link.text, link['href']\n",
    "                gamelog[url + team] = [url] + [team] + [i.text for i in items]\n",
    "    return gamelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_gamelog_advanced(season_teams, season):\n",
    "    '''\n",
    "    This grabs the gamelogs with ADVANCED STATS for all teams, for the season that is specified.\n",
    "    \n",
    "    Note this is exactly the same as the grab_gamelog function, except goes to a different website\n",
    "    \n",
    "    Input: Dictionary where the keys are the teams for specified season; specified season\n",
    "    Output: A dictionary, where each key stores a season's worth of individual game statistics for one team;\n",
    "            The dictionary will hold all teams' information\n",
    "    \n",
    "    '''\n",
    "    gamelog = {}\n",
    "    for key in season_teams:\n",
    "        game_url = \"https://www.sports-reference.com\" + season_teams[key][0] + str(season) +\"-gamelogs-advanced.html\"\n",
    "        game_response = requests.get(game_url)\n",
    "        gamelog_text = game_response.text\n",
    "        gamelog_soup = BeautifulSoup(gamelog_text,\"lxml\")\n",
    "        gamelog_table = gamelog_soup.find('table')\n",
    "        gamelog_rows = gamelog_table.find_all('tr')\n",
    "        team = re.split(\"\\/\",season_teams[key][0])[3]\n",
    "        for i in [i for i in range(2,len(gamelog_rows)) if i % 22 != 0 and i % 23 != 0 and i % 44 != 0 and i % 45 != 0]:\n",
    "            items = gamelog_rows[i].find_all('td')\n",
    "            link = items[0].find('a')\n",
    "            if link == None:\n",
    "                pass\n",
    "            else:\n",
    "                date, url = link.text, link['href']\n",
    "                gamelog[url + team] = [url] + [team] + [i.text for i in items]\n",
    "    return gamelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(gamelog, advanced_gamelog):\n",
    "    '''\n",
    "    Combines the two dictionaries so that there is a single dictionary housing both basic and advanced stats\n",
    "    '''\n",
    "    combo_log = {}\n",
    "    for game in gamelog.keys():\n",
    "        gamelog[game].extend(advanced_gamelog[game])\n",
    "    return gamelog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Line Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_data(year_nums):\n",
    "    \"\"\"\n",
    "    Helper function to load data from http://www.thepredictiontracker.com/basketball.php\n",
    "    \"\"\"\n",
    "    url = \"http://www.thepredictiontracker.com/ncaabb{}.csv\"\n",
    "    dfs = []\n",
    "    for year in year_nums:\n",
    "        file_url = url.format(year-1)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = get_line_data([14,15,16,17,18,19])\n",
    "with open(f'lines.pickle', 'wb') as handle:\n",
    "    pickle.dump(lines, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE TO GRAB THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull multiple seasons\n",
    "\n",
    "my_seasons = [2015, 2019]\n",
    "\n",
    "for i in my_seasons:\n",
    "    this_season = teams(teams_list, i)\n",
    "    \n",
    "    this_gamelog = grab_gamelog(this_season, i)\n",
    "    with open(f'gamelog_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(this_gamelog, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'gamelog {i}')        \n",
    "        \n",
    "    this_advanced_gamelog = grab_gamelog_advanced(this_season, i)\n",
    "    with open(f'advanced_gamelog_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(this_advanced_gamelog, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'advanced_gamelog {i}')  \n",
    "    \n",
    "    this_combo_log = combine(this_gamelog, this_advanced_gamelog)\n",
    "    with open(f'combo_log_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(this_combo_log, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'done with {i} season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
