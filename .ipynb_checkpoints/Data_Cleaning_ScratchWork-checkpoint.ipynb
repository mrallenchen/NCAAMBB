{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for results, which will be used for further calculations\n",
    "r_keys = ['L', 'W', 'L\\xa0(1 OT)', 'L\\xa0(2 OT)', 'W\\xa0(2 OT)','W\\xa0(1 OT)', 'W\\xa0(3 OT)', 'L\\xa0(3 OT)', 'W\\xa0(4 OT)', 'L\\xa0(4 OT)']\n",
    "r_wins = [0,1,0,0,1,1,1,0,1,0] #1 for win\n",
    "r_OT = [0,0,1,2,2,1,3,3,4,4] #overtimes played\n",
    "r_MP = [40,40,45,50,50,45,55,55,60,60] #minutes played\n",
    "\n",
    "results_dict = dict(zip(r_keys,zip(r_wins,r_OT,r_MP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_lookup = pickle.load(open('teams_lookup.pickle', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names for dataframes\n",
    "combo_col_w_blank = ['url','Team','Date','Court','Opponent','Result','Tm','Opp','FG','FGA','FG%','3P','3PA','3P%','FT','FTA',\n",
    "           'FT%','ORB','TRB','AST','STL','BLK','TOV','PF','blank','FG_O','FGA_O','FG%_O','3P_O','3PA_O','3P%_O','FT_O',\n",
    "           'FTA_O','FT%_O','ORB_O','TRB_O','AST_O','STL_O','BLK_O','TOV_O','PF_O','url2','Team2','Date2','Court2','Opponent2','Result2','Tm2','Opp2','ORtg','DRtg','Pace','FTr','3PAr','TS%','TRB%',\n",
    "           'AST%','STL%','BLK%','blank1','OeFG%','OTOV%','ORB%','OFT/FGA','blank2','DeFG%','DTOV%','DRB%','DFT/FGA']\n",
    "num_cols = ['Tm','Opp','FG','FGA','FG%','3P','3PA','3P%','FT','FTA',\n",
    "           'FT%','ORB','TRB','AST','STL','BLK','TOV','PF','FG_O','FGA_O','FG%_O','3P_O','3PA_O','3P%_O','FT_O',\n",
    "           'FTA_O','FT%_O','ORB_O','TRB_O','AST_O','STL_O','BLK_O','TOV_O','PF_O','ORtg','DRtg','Pace','FTr','3PAr','TS%','TRB%',\n",
    "           'AST%','STL%','BLK%','OeFG%','OTOV%','ORB%','OFT/FGA','DeFG%','DTOV%','DRB%','DFT/FGA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gamelog(combo_log, col_names_wb = combo_col_w_blank,\n",
    "                  col_names = num_cols):\n",
    "    '''\n",
    "    Takes in gamelog and cleans the data\n",
    "    input: gamelog as dataframe and stat_type. stat_type can be basic or advanced\n",
    "    output: dataframe with clean gamelog\n",
    "    '''\n",
    "    games = pd.DataFrame.from_dict(combo_log, orient = \"index\")\n",
    "    games.columns = col_names_wb\n",
    "    games['Date'] = pd.to_datetime(games['Date'])\n",
    "    games = games.drop(columns=['blank','url2','Team2','Date2','Court2','Opponent2','Result2','Tm2','Opp2','blank1','blank2'])\n",
    "    for i in col_names:\n",
    "        games[i] = pd.to_numeric(games[i])\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding columns to help with further data manipulation\n",
    "def helper_columns(combo_log,team_lookup):\n",
    "    '''\n",
    "    this helps to clean data. update this here\n",
    "    games = gamelog information by team ______\n",
    "    columns = names of columns in the dataframe\n",
    "    team_lookup = to get the right name\n",
    "    \n",
    "    output: dataframe cleaned!\n",
    "    with columns we want\n",
    "    \n",
    "    '''\n",
    "    hot_court = pd.get_dummies(combo_log.Court)\n",
    "    combo_log['Home'],combo_log['Away'] = hot_court[\"\"],hot_court[\"@\"]\n",
    "    combo_log['Wins'] = [results_dict[x][0] for x in combo_log.Result]\n",
    "    combo_log['OT'] = [results_dict[x][1] for x in combo_log.Result]\n",
    "    combo_log['MP']= [results_dict[x][2] for x in combo_log.Result]\n",
    "    return combo_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D1_only(combo_log, team_lookup):\n",
    "    '''\n",
    "    Removes teams who are not in D1 \n",
    "    \n",
    "    '''\n",
    "    #create lookup for D1 feature gen\n",
    "    #D1 = indicate if opponent is in Division 1 or not (from the data collection, only D1 teams included for gamelog but they sometimes play non-D1 schools)\n",
    "\n",
    "    team_df = pd.DataFrame.from_dict(team_lookup, orient = 'index')\n",
    "    D1 = dict(zip(team_df.loc[:,0],np.repeat(1,len(team_df.loc[:,0]))))\n",
    "\n",
    "    #removing all non-D1 games\n",
    "    combo_log['D1'] = [D1.get(x) or 0 for x in combo_log['Opponent']]\n",
    "    combo_log = combo_log[combo_log.D1 == 1]\n",
    "    \n",
    "    return combo_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate various spreads\n",
    "\n",
    "def calc_spreads(df):\n",
    "    df['P_S'] = df.eval('Tm - Opp')\n",
    "    df['FG_S'] = df.eval('FG - FG_O')\n",
    "    df['FGA_S'] = df.eval('FGA - FGA_O')\n",
    "    df['FG%_S'] = df['FG%'] - df['FG%_O']\n",
    "    df['3P_S'] = df['3P'] - df['3P_O']\n",
    "    df['3PA_S'] = df['3PA'] - df['3PA_O']\n",
    "    df['3P%_S'] = df['3P%'] - df['3P%_O']\n",
    "    df['FT_S'] = df.eval('FT - FT_O')\n",
    "    df['FTA_S'] = df.eval('FTA - FTA_O')\n",
    "    df['FT%_S'] = df['FT%'] - df['FT%_O']\n",
    "    df['TRB_S'] = df.eval('TRB- TRB_O')\n",
    "    df['AST_S'] = df.eval('AST - AST_O')\n",
    "    df['STL_S'] = df.eval('STL - STL_O')\n",
    "    df['BLK_S'] = df.eval('BLK - BLK_O')\n",
    "    df['TOV_S'] = df.eval('TOV - TOV_O')\n",
    "    df['PF_S'] = df.eval('PF - PF_O')\n",
    "    df['FTr_S'] = df.eval('FTr - FT_O/FGA_O') \n",
    "    df['3PAr_S'] = df['3PA']/df['FG'] - df['3PA_O']/df['FG_O']\n",
    "    df['TS%_S'] = df['TS%'] - df.eval('Opp/(2*(FGA_O+0.44*FTA_O))')\n",
    "    df['TRB%_S'] = 2*df['TRB%'] - 1\n",
    "    df['AST%_S'] = df.eval('(AST - AST_O)/Pace')\n",
    "    df['STL%_S'] = df.eval('(STL - STL_O)/Pace')\n",
    "    df['BLK%_S'] = df.eval('(BLK - BLK_O)/Pace')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing clean data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_df(games):\n",
    "    '''\n",
    "    This will compute the running stats for teams, with season-to-date info prior to each game\n",
    "    '''\n",
    "    df = pd.DataFrame(games['url'])\n",
    "    df['Team'] = [team_lookup[x][0] for x in games['Team']]\n",
    "    df['Date'] = games['Date']\n",
    "    df['Opponent'] = games['Opponent']\n",
    "    df['Spread'] = games['P_S']\n",
    "    df['Win_Loss'] = games['Wins']\n",
    "    df['Home'] = games['Home']\n",
    "    df['Away'] = games['Away']\n",
    "    \n",
    "    # GP = Games Played prior to this game\n",
    "    df['GP'] = games.groupby('Team')['Team'].transform(lambda x: x.expanding().count()-1)\n",
    "    # get prior average stats for each team before the game\n",
    "    for i in ['Wins','Tm', 'Opp', 'FG',\n",
    "       'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB',\n",
    "       'AST', 'STL', 'BLK', 'TOV', 'PF', 'ORtg', 'DRtg', 'Pace', 'FTr',\n",
    "       '3PAr', 'TS%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'OeFG%', 'OTOV%', 'ORB%',\n",
    "       'OFT/FGA', 'DeFG%', 'DTOV%', 'DRB%', 'DFT/FGA','P_S', 'FG_S', 'FGA_S', 'FG%_S', '3P_S', '3PA_S',\n",
    "       '3P%_S', 'FT_S', 'FTA_S', 'FT%_S', 'TRB_S', 'AST_S', 'STL_S', 'BLK_S','TOV_S', 'PF_S', 'FTr_S', '3PAr_S', 'TS%_S', 'TRB%_S', 'AST%_S',\n",
    "       'STL%_S', 'BLK%_S']:\n",
    "        df[i] = games.groupby('Team')[i].transform(lambda x: x.expanding().sum()-x)/df['GP']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append (vs) Opponent Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vs_df(df):\n",
    "    '''\n",
    "    This will compute the running stats for teams, with season-to-date info prior to each game\n",
    "    '''\n",
    "    # GP = Games Played prior to this game\n",
    "    winners = df[df.Win_Loss == 1]\n",
    "    losers = df[df.Win_Loss == 0]\n",
    "    \n",
    "    winner_merge = pd.merge(winners, losers, left_on='url',right_on='url',how='outer',suffixes=('','_vs'))\n",
    "    loser_merge = pd.merge(losers, winners, left_on='url',right_on='url',how='outer',suffixes=('','_vs'))\n",
    "    final = pd.concat([winner_merge,loser_merge])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups(df):\n",
    "    '''\n",
    "    remove the second instance of each game, where the teams are just flipped\n",
    "    \n",
    "    '''\n",
    "    df_urlsort = df.sort_values('url')\n",
    "    \n",
    "    total = len(df_urlsort)\n",
    "    unique = len(df_urlsort.url.unique())\n",
    "    check = (total/unique == 2) \n",
    "    print(f'total games: {total} unique games: {unique} check: {check}')\n",
    "    \n",
    "    df_final = df_urlsort.iloc[range(0,len(df_urlsort),2),]\n",
    "    total = len(df_final)\n",
    "    unique = len(df_final.url.unique())\n",
    "    check = (total == unique) \n",
    "    print(f'games kept: {total} unique games: {unique} check: {check}')\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total games: 11016 unique games: 5508 check: True\n",
      "games kept: 5508 unique games: 5508 check: True\n",
      "total games: 10998 unique games: 5499 check: True\n",
      "games kept: 5499 unique games: 5499 check: True\n",
      "total games: 11032 unique games: 5516 check: True\n",
      "games kept: 5516 unique games: 5516 check: True\n",
      "total games: 11070 unique games: 5535 check: True\n",
      "games kept: 5535 unique games: 5535 check: True\n",
      "total games: 11078 unique games: 5539 check: True\n",
      "games kept: 5539 unique games: 5539 check: True\n",
      "total games: 11206 unique games: 5603 check: True\n",
      "games kept: 5603 unique games: 5603 check: True\n"
     ]
    }
   ],
   "source": [
    "my_seasons = [2014,2015,2016,2017,2018,2019]\n",
    "for i in my_seasons:\n",
    "    team_lookup = pickle.load(open(f'team_lookup_{i}.pickle', \"rb\"))\n",
    "    combo_log = pickle.load(open(f'combo_log_{i}.pickle', \"rb\"))\n",
    "    combo_log = clean_gamelog(combo_log)\n",
    "    combo_log = helper_columns(combo_log,team_lookup)\n",
    "    combo_log = D1_only(combo_log, team_lookup) #removes non-D1 opponents\n",
    "    combo_log = calc_spreads(combo_log) #calculates the spreads between team and opponent for each game\n",
    "    with open(f'clean_combo_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(combo_log, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    df = agg_df(combo_log) #calculates running season to date info for each game\n",
    "    df = vs_df(df) #adds opponent info\n",
    "    df = remove_dups(df)\n",
    "    with open(f'final_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total games: 11016 unique games: 5508 check: True\n",
      "games kept: 5508 unique games: 5508 check: True\n",
      "total games: 10998 unique games: 5499 check: True\n",
      "games kept: 5499 unique games: 5499 check: True\n",
      "total games: 11032 unique games: 5516 check: True\n",
      "games kept: 5516 unique games: 5516 check: True\n",
      "total games: 11070 unique games: 5535 check: True\n",
      "games kept: 5535 unique games: 5535 check: True\n",
      "total games: 11078 unique games: 5539 check: True\n",
      "games kept: 5539 unique games: 5539 check: True\n",
      "total games: 11206 unique games: 5603 check: True\n",
      "games kept: 5603 unique games: 5603 check: True\n"
     ]
    }
   ],
   "source": [
    "my_seasons = [2014,2015,2016,2017,2018,2019]\n",
    "for i in my_seasons:\n",
    "    clean_combo_log = pickle.load(open(f'clean_combo_{i}.pickle', \"rb\"))\n",
    "    df = agg_df(clean_combo_log) #calculates running season to date info for each game\n",
    "    df = vs_df(df) #adds opponent info\n",
    "    df = remove_dups(df)\n",
    "    with open(f'final_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding line information - FUTURE WORK\n",
    "below code can be used as starter but is not functional. sometimes gets the sign wrong. would need to correct for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pickle.load(open('lines.pickle', \"rb\"))\n",
    "lines.date = pd.to_datetime(lines.date)\n",
    "lines.reset_index(drop=True)\n",
    "line_school_dict = pd.read_csv('line_school_dict.csv')\n",
    "school_lookup = dict(zip(line_school_dict.Lines,line_school_dict.Log))\n",
    "\n",
    "home_fix = []\n",
    "for i in range(len(lines)):\n",
    "    try:\n",
    "        home_fix.append(school_lookup[lines.iloc[i,1]])\n",
    "    except KeyError:\n",
    "        home_fix.append(None)\n",
    "        \n",
    "lines['home']=home_fix\n",
    "small_lines = lines.loc[:,['date','home','line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url                 object\n",
      "Team                object\n",
      "Date        datetime64[ns]\n",
      "Opponent            object\n",
      "Spread               int64\n",
      "                 ...      \n",
      "line_x             float64\n",
      "line_y             float64\n",
      "line_x             float64\n",
      "line_y             float64\n",
      "line               float64\n",
      "Length: 142, dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bf4048964964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'line'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'line_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'line_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcombine_first\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5579\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombiner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m     def update(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mcombine\u001b[0;34m(self, other, func, fill_value, overwrite)\u001b[0m\n\u001b[1;32m   5462\u001b[0m             \u001b[0motherSeries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5464\u001b[0;31m             \u001b[0mthis_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5465\u001b[0m             \u001b[0mother_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0motherSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "my_seasons = [2014,2015,2016,2017,2018,2019]\n",
    "for i in my_seasons:\n",
    " \n",
    "    df = pickle.load(open(f'final_{i}.pickle', \"rb\"))\n",
    "    df = pd.merge(df, small_lines, how = 'left', left_on = ['Date','Team'], right_on = ['date','home'], right_index=False)\n",
    "    df = pd.merge(df, small_lines, how = 'left', left_on = ['Date','Opponent'], right_on = ['date','home'], right_index=False)\n",
    "    df = df.drop(columns=['date_x','home_x','date_y','home_y'])\n",
    "    line = df.line_x.combine_first(df.line_y)\n",
    "    df['line'] = line\n",
    "    df = df.drop(columns=['line_x', 'line_y'])   \n",
    "    with open(f'final_{i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home</th>\n",
       "      <th>hscore</th>\n",
       "      <th>road</th>\n",
       "      <th>rscore</th>\n",
       "      <th>line</th>\n",
       "      <th>lineavg</th>\n",
       "      <th>linesag</th>\n",
       "      <th>linesage</th>\n",
       "      <th>linesagp</th>\n",
       "      <th>...</th>\n",
       "      <th>linepib</th>\n",
       "      <th>line7ot</th>\n",
       "      <th>lineer</th>\n",
       "      <th>linedd</th>\n",
       "      <th>linemassey</th>\n",
       "      <th>lineespn</th>\n",
       "      <th>linedunk</th>\n",
       "      <th>lineround</th>\n",
       "      <th>lineteamrnks</th>\n",
       "      <th>linetalis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Army</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>NC State</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Appalachian St.</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.23</td>\n",
       "      <td>16.78</td>\n",
       "      <td>16.78</td>\n",
       "      <td>16.78</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Providence</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Texas A&amp;M</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.68</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Cal Poly SLO</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.89</td>\n",
       "      <td>17.58</td>\n",
       "      <td>17.58</td>\n",
       "      <td>17.58</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DePaul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Florida</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.77</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>DePaul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Florida</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.77</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.84</td>\n",
       "      <td>-4.13</td>\n",
       "      <td>4.89</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.21</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>3.22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25411 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date            home  hscore             road  rscore  line  \\\n",
       "0    2013-11-08            Army    68.0        Air Force    79.0   3.5   \n",
       "1    2013-11-08        NC State    98.0  Appalachian St.    77.0  14.0   \n",
       "2    2013-11-08      Providence    82.0   Boston College    78.0   3.0   \n",
       "3    2013-11-08       Texas A&M    82.0          Buffalo    58.0   6.0   \n",
       "4    2013-11-08         Arizona    73.0     Cal Poly SLO    62.0  16.5   \n",
       "...         ...             ...     ...              ...     ...   ...   \n",
       "5559 2019-04-05          DePaul     NaN    South Florida     1.0   1.0   \n",
       "5560 2019-04-05          DePaul     NaN    South Florida     1.0   1.0   \n",
       "5561 2019-04-06  Michigan State     NaN       Texas Tech     2.0   2.0   \n",
       "5562 2019-04-06        Virginia     NaN           Auburn     6.0   6.0   \n",
       "5563 2019-04-08        Virginia     NaN       Texas Tech     1.5   1.5   \n",
       "\n",
       "      lineavg  linesag  linesage  linesagp  ...  linepib  line7ot  lineer  \\\n",
       "0       -2.16    -0.97     -0.97     -0.97  ...      NaN      NaN     NaN   \n",
       "1       18.23    16.78     16.78     16.78  ...      NaN      NaN     NaN   \n",
       "2        3.55     3.50      3.50      3.50  ...      NaN      NaN     NaN   \n",
       "3        7.65     5.68      5.68      5.68  ...      NaN      NaN     NaN   \n",
       "4       18.89    17.58     17.58     17.58  ...      NaN      NaN     NaN   \n",
       "...       ...      ...       ...       ...  ...      ...      ...     ...   \n",
       "5559     3.23     2.28      2.48      2.25  ...      NaN      3.0     NaN   \n",
       "5560     3.00     2.28      2.48      2.25  ...      NaN      3.0     NaN   \n",
       "5561     1.72     2.93      0.50      3.03  ...      NaN      1.0     NaN   \n",
       "5562     4.02     4.84     -4.13      4.89  ...      NaN      8.0     NaN   \n",
       "5563     1.84     3.21     -1.53      3.22  ...      NaN      5.0     NaN   \n",
       "\n",
       "      linedd  linemassey  lineespn  linedunk  lineround  lineteamrnks  \\\n",
       "0        NaN         NaN       NaN       NaN        NaN           NaN   \n",
       "1        NaN         NaN       NaN       NaN        NaN           NaN   \n",
       "2        NaN         NaN       NaN       NaN        NaN           NaN   \n",
       "3        NaN         NaN       NaN       NaN        NaN           NaN   \n",
       "4        NaN         NaN       NaN       NaN        NaN           NaN   \n",
       "...      ...         ...       ...       ...        ...           ...   \n",
       "5559     NaN        3.26       NaN      4.77        2.0           2.1   \n",
       "5560     NaN        3.26       NaN      4.77        2.0           2.1   \n",
       "5561     NaN        1.89       NaN      2.19        1.0           2.1   \n",
       "5562     NaN        3.01       NaN      5.30        5.0           5.0   \n",
       "5563     NaN       -0.59       NaN      3.06        NaN           3.2   \n",
       "\n",
       "      linetalis  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "5559        3.4  \n",
       "5560        0.1  \n",
       "5561        2.9  \n",
       "5562        5.3  \n",
       "5563        NaN  \n",
       "\n",
       "[25411 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['actual'] = lines.hscore-lines.rscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['error'] = abs(lines.line-lines.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9306625577812015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lines.line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
