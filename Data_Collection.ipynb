{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab names for all NCAA teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sports-reference.com/cbb/schools/\"\n",
    "response = requests.get(url)\n",
    "teams_text = response.text\n",
    "team_soup = BeautifulSoup(teams_text, \"lxml\")\n",
    "team_table = team_soup.find('table')\n",
    "team_rows = team_table.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that after every 20 teams, there is another header row\n",
    "teams = {}\n",
    "for i in [i for i in range(1,len(team_rows)) if i % 21 != 0]:\n",
    "    items = team_rows[i].find_all('td')\n",
    "    link = items[0].find('a')\n",
    "    school, url = link.text, link['href']\n",
    "    teams[school] = [url] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('teams_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(teams, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find teams in D1 for particular season\n",
    "season = 2019\n",
    "season_teams = []\n",
    "for team in teams.keys():\n",
    "    if int(teams[team][3]) <= season <= int(teams[team][4]):\n",
    "        season_teams.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create team_lookup for names - url name as key, values include name, formal name, and team url\n",
    "team_lookup = {}\n",
    "for key in season_teams:\n",
    "    sched_url = \"https://www.sports-reference.com\" + teams[key][0] + str(season) +\"-schedule.html\"\n",
    "    sched_response = requests.get(sched_url)\n",
    "    sched_text = sched_response.text\n",
    "    sched_soup = BeautifulSoup(sched_text,\"lxml\")\n",
    "    sched_table = sched_soup.find('table')\n",
    "    simple_name = re.split(\"\\/\",teams[key][0])[3]\n",
    "    sched_rows = sched_table.find_all('tr')\n",
    "    name = sched_table.find('a').text\n",
    "    formal_name = teams[key][1]\n",
    "    team_lookup[simple_name] = [name] + [formal_name] + [teams[key][0]]\n",
    "with open('teams_lookup.pickle', 'wb') as handle:\n",
    "    pickle.dump(team_lookup, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAB gamelogs for each team for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamelog = {}\n",
    "for key in season_teams:\n",
    "    game_url = \"https://www.sports-reference.com\" + teams[key][0] + str(season) +\"-gamelogs.html\"\n",
    "    game_response = requests.get(game_url)\n",
    "    gamelog_text = game_response.text\n",
    "    gamelog_soup = BeautifulSoup(gamelog_text,\"lxml\")\n",
    "    gamelog_table = gamelog_soup.find('table')\n",
    "    gamelog_rows = gamelog_table.find_all('tr')\n",
    "    team = re.split(\"\\/\",teams[key][0])[3]\n",
    "    for i in [i for i in range(2,len(gamelog_rows)) if i % 22 != 0 and i % 23 != 0 ]:\n",
    "        items = gamelog_rows[i].find_all('td')\n",
    "        link = items[0].find('a')\n",
    "        date, url = link.text, link['href']\n",
    "        gamelog[url + team] = [url] + [team] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gamelog.pickle', 'wb') as handle:\n",
    "    pickle.dump(gamelog, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_gamelog = {}\n",
    "for key in season_teams:\n",
    "    game_url = \"https://www.sports-reference.com\" + teams[key][0] + str(season) +\"-gamelogs-advanced.html\"\n",
    "    advanced_game_response = requests.get(game_url)\n",
    "    advanced_gamelog_text = advanced_game_response.text\n",
    "    advanced_gamelog_soup = advanced_BeautifulSoup(gamelog_text,\"lxml\")\n",
    "    advanced_gamelog_table = advanced_gamelog_soup.find('table')\n",
    "    advanced_gamelog_rows = advanced_gamelog_table.find_all('tr')\n",
    "    team = re.split(\"\\/\",teams[key][0])[3]\n",
    "    for i in [i for i in range(2,len(advanced_gamelog_rows)) if i % 22 != 0 and i % 23 != 0 ]:\n",
    "        items = advanced_gamelog_rows[i].find_all('td')\n",
    "        link = items[0].find('a')\n",
    "        date, url = link.text, link['href']\n",
    "        advanced_gamelog[url + team] = [url] + [team] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('advanced_gamelog.pickle', 'wb') as handle:\n",
    "    pickle.dump(advanced_gamelog, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAB URL FOR ALL GAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab data from single game - hold off on pulling individual game data for now\n",
    "\n",
    "Input url for each game\n",
    "Output data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sports-reference.com/cbb/boxscores/2020-03-11-21-stanford.html'\n",
    "\n",
    "box = requests.get(url)\n",
    "boxscores = box.text\n",
    "soup = BeautifulSoup(boxscores, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "#note this will grab 8 tables (the last 4 will be basic and advanced stats, for each team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull Data from class \"scorebox_meta\": Date, Location <- this does not show up in a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull Data from table \"line-score\": <- this also does not show up in a table...\n",
    "Output: Away Team, Home Team, Away Score 1H, Away Score 2H, Away Score F, Home Score 1H, Home Score 2h, Home Score F\n",
    "\n",
    "? What about overtimes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case for gamelogs\n",
    "cal_url = \"https://www.sports-reference.com/cbb/schools/california/2019-gamelogs.html\"\n",
    "cal_response = requests.get(cal_url)\n",
    "gamelog_text = cal_response.text\n",
    "gamelog_soup = BeautifulSoup(gamelog_text,\"lxml\")\n",
    "gamelog_table = gamelog_soup.find('table')\n",
    "gamelog_rows = gamelog_table.find_all('tr')\n",
    "#test case continued\n",
    "cal_log = {}\n",
    "team = 'california'\n",
    "for i in [i for i in range(2,len(gamelog_rows)) if i % 22 != 0 and i % 23 != 0 ]:\n",
    "    items = gamelog_rows[i].find_all('td')\n",
    "    link = items[0].find('a')\n",
    "    date, url = link.text, link['href']\n",
    "    cal_log[url + team] = [url] + [team] + [i.text for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
